{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "from scipy.io import wavfile as wav\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>FSID</th>\n",
       "      <th>Maximum_Amplitude</th>\n",
       "      <th>Minimum_Amplitude</th>\n",
       "      <th>Start Time in original File(Sec)</th>\n",
       "      <th>End Time in orignal File(Sec)</th>\n",
       "      <th>Class ID</th>\n",
       "      <th>fold</th>\n",
       "      <th>class</th>\n",
       "      <th>Location on drive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ball_Bounce_On_Ground.wav001_user.wav</td>\n",
       "      <td>211213</td>\n",
       "      <td>0.608783</td>\n",
       "      <td>-0.274387</td>\n",
       "      <td>[[4.65487528]]</td>\n",
       "      <td>[[4.95482993]]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Ball Ground Hit</td>\n",
       "      <td>C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ball_Bounce_On_Ground.wav002_user.wav</td>\n",
       "      <td>211213</td>\n",
       "      <td>0.688888</td>\n",
       "      <td>-0.962503</td>\n",
       "      <td>[[ 21.5752381 404.8645805]]</td>\n",
       "      <td>[[21.87519274]]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Ball Ground Hit</td>\n",
       "      <td>C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ball_Bounce_On_Ground.wav003_user.wav</td>\n",
       "      <td>211213</td>\n",
       "      <td>0.669433</td>\n",
       "      <td>-0.694868</td>\n",
       "      <td>[[23.8215873]]</td>\n",
       "      <td>[[24.12154195]]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Ball Ground Hit</td>\n",
       "      <td>C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ball_Bounce_On_Ground.wav004_user.wav</td>\n",
       "      <td>211213</td>\n",
       "      <td>0.597916</td>\n",
       "      <td>-0.766195</td>\n",
       "      <td>[[24.99750567]]</td>\n",
       "      <td>[[25.29746032]]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Ball Ground Hit</td>\n",
       "      <td>C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ball_Bounce_On_Ground.wav005_user.wav</td>\n",
       "      <td>211213</td>\n",
       "      <td>0.552153</td>\n",
       "      <td>-0.623119</td>\n",
       "      <td>[[30.62698413]]</td>\n",
       "      <td>[[30.92693878]]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Ball Ground Hit</td>\n",
       "      <td>C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         slice_file_name    FSID  Maximum_Amplitude  \\\n",
       "0  Ball_Bounce_On_Ground.wav001_user.wav  211213           0.608783   \n",
       "1  Ball_Bounce_On_Ground.wav002_user.wav  211213           0.688888   \n",
       "2  Ball_Bounce_On_Ground.wav003_user.wav  211213           0.669433   \n",
       "3  Ball_Bounce_On_Ground.wav004_user.wav  211213           0.597916   \n",
       "4  Ball_Bounce_On_Ground.wav005_user.wav  211213           0.552153   \n",
       "\n",
       "   Minimum_Amplitude Start Time in original File(Sec)  \\\n",
       "0          -0.274387                   [[4.65487528]]   \n",
       "1          -0.962503      [[ 21.5752381 404.8645805]]   \n",
       "2          -0.694868                   [[23.8215873]]   \n",
       "3          -0.766195                  [[24.99750567]]   \n",
       "4          -0.623119                  [[30.62698413]]   \n",
       "\n",
       "  End Time in orignal File(Sec)  Class ID  fold            class  \\\n",
       "0                [[4.95482993]]         2     1  Ball Ground Hit   \n",
       "1               [[21.87519274]]         2     1  Ball Ground Hit   \n",
       "2               [[24.12154195]]         2     1  Ball Ground Hit   \n",
       "3               [[25.29746032]]         2     1  Ball Ground Hit   \n",
       "4               [[30.92693878]]         2     1  Ball Ground Hit   \n",
       "\n",
       "                                   Location on drive  \n",
       "0  C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...  \n",
       "1  C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...  \n",
       "2  C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...  \n",
       "3  C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...  \n",
       "4  C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading metadata from csv file \n",
    "metadatafilefolder = '/home/arvindn/drive/' #Please change this to an appropriate location for your work\n",
    "metadata = pd.read_csv(metadatafilefolder+'BG_BR.csv')\n",
    "\n",
    "#printing metadata \n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ball Ground Hit    754\n",
       "Ball Racket Hit    694\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for imbalance dataset\n",
    "#if the difference in numbers of files is significant then our data will be consider as imbalanced data\n",
    "metadata['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>FSID</th>\n",
       "      <th>Maximum_Amplitude</th>\n",
       "      <th>Minimum_Amplitude</th>\n",
       "      <th>Start Time in original File(Sec)</th>\n",
       "      <th>End Time in orignal File(Sec)</th>\n",
       "      <th>Class ID</th>\n",
       "      <th>fold</th>\n",
       "      <th>class</th>\n",
       "      <th>Location on drive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ball_Bounce_On_Ground.wav001_user.wav</td>\n",
       "      <td>211213</td>\n",
       "      <td>0.608783</td>\n",
       "      <td>-0.274387</td>\n",
       "      <td>[[4.65487528]]</td>\n",
       "      <td>[[4.95482993]]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Ball Ground Hit</td>\n",
       "      <td>C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ball_Bounce_On_Ground.wav002_user.wav</td>\n",
       "      <td>211213</td>\n",
       "      <td>0.688888</td>\n",
       "      <td>-0.962503</td>\n",
       "      <td>[[ 21.5752381 404.8645805]]</td>\n",
       "      <td>[[21.87519274]]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Ball Ground Hit</td>\n",
       "      <td>C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ball_Bounce_On_Ground.wav003_user.wav</td>\n",
       "      <td>211213</td>\n",
       "      <td>0.669433</td>\n",
       "      <td>-0.694868</td>\n",
       "      <td>[[23.8215873]]</td>\n",
       "      <td>[[24.12154195]]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Ball Ground Hit</td>\n",
       "      <td>C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ball_Bounce_On_Ground.wav004_user.wav</td>\n",
       "      <td>211213</td>\n",
       "      <td>0.597916</td>\n",
       "      <td>-0.766195</td>\n",
       "      <td>[[24.99750567]]</td>\n",
       "      <td>[[25.29746032]]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Ball Ground Hit</td>\n",
       "      <td>C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ball_Bounce_On_Ground.wav005_user.wav</td>\n",
       "      <td>211213</td>\n",
       "      <td>0.552153</td>\n",
       "      <td>-0.623119</td>\n",
       "      <td>[[30.62698413]]</td>\n",
       "      <td>[[30.92693878]]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Ball Ground Hit</td>\n",
       "      <td>C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         slice_file_name    FSID  Maximum_Amplitude  \\\n",
       "0  Ball_Bounce_On_Ground.wav001_user.wav  211213           0.608783   \n",
       "1  Ball_Bounce_On_Ground.wav002_user.wav  211213           0.688888   \n",
       "2  Ball_Bounce_On_Ground.wav003_user.wav  211213           0.669433   \n",
       "3  Ball_Bounce_On_Ground.wav004_user.wav  211213           0.597916   \n",
       "4  Ball_Bounce_On_Ground.wav005_user.wav  211213           0.552153   \n",
       "\n",
       "   Minimum_Amplitude Start Time in original File(Sec)  \\\n",
       "0          -0.274387                   [[4.65487528]]   \n",
       "1          -0.962503      [[ 21.5752381 404.8645805]]   \n",
       "2          -0.694868                   [[23.8215873]]   \n",
       "3          -0.766195                  [[24.99750567]]   \n",
       "4          -0.623119                  [[30.62698413]]   \n",
       "\n",
       "  End Time in orignal File(Sec)  Class ID  fold            class  \\\n",
       "0                [[4.95482993]]         2     1  Ball Ground Hit   \n",
       "1               [[21.87519274]]         2     1  Ball Ground Hit   \n",
       "2               [[24.12154195]]         2     1  Ball Ground Hit   \n",
       "3               [[25.29746032]]         2     1  Ball Ground Hit   \n",
       "4               [[30.92693878]]         2     1  Ball Ground Hit   \n",
       "\n",
       "                                   Location on drive  \n",
       "0  C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...  \n",
       "1  C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...  \n",
       "2  C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...  \n",
       "3  C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...  \n",
       "4  C:/Users/Ankit Kumar/Audio_Data/BallBounceOnGr...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading csv file \n",
    "audio_dataset_path = metadatafilefolder + 'Audio/'\n",
    "metadata=pd.read_csv(metadatafilefolder+'BG_BR.csv')\n",
    "#printing metadata \n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the mel-frequency cepstrum (MFC) is a representation of the short-term power spectrum of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency.\n",
    "# n_mfcc = number of MFCCs to return\n",
    "#sr = sample rate, y =audio time series\n",
    "\n",
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate,n_mfcc = 40)\n",
    "    mfccs_scaled_features=np.mean(mfccs_features.T, axis=0)\n",
    "    return mfccs_scaled_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1448it [28:18,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "### Now we iterate through every audio file and extract features \n",
    "### using Mel-Frequency Cepstral Coefficients\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    final_class_labels=row[\"class\"]\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe  from the list of etracted features\n",
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-218.40462, 153.12389, -25.449078, 22.280703,...</td>\n",
       "      <td>Ball Ground Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-252.92578, 142.6328, -23.307566, 17.159676, ...</td>\n",
       "      <td>Ball Ground Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-270.47318, 151.5141, -31.51296, 22.09384, 13...</td>\n",
       "      <td>Ball Ground Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-263.1113, 145.61594, -30.467701, 20.84265, 1...</td>\n",
       "      <td>Ball Ground Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-270.6276, 146.31517, -32.099884, 19.047443, ...</td>\n",
       "      <td>Ball Ground Hit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature            class\n",
       "0  [-218.40462, 153.12389, -25.449078, 22.280703,...  Ball Ground Hit\n",
       "1  [-252.92578, 142.6328, -23.307566, 17.159676, ...  Ball Ground Hit\n",
       "2  [-270.47318, 151.5141, -31.51296, 22.09384, 13...  Ball Ground Hit\n",
       "3  [-263.1113, 145.61594, -30.467701, 20.84265, 1...  Ball Ground Hit\n",
       "4  [-270.6276, 146.31517, -32.099884, 19.047443, ...  Ball Ground Hit"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing dataframe and saving it into csv for better understanding\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the dataset into independent and dependent dataset\n",
    "X=np.array(extracted_features_df['feature'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the dataset into independent and dependent dataset\n",
    "y = np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding refers to converting the labels into numeric form so as to convert it into the machine-readable form. \n",
    "y=np.array(pd.get_dummies(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting dataset into test and train data\n",
    "#random state = 0 (random datasets would be taken each time we will run the program)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shape:  (1158, 40)\n",
      "X_test:  (290, 40)\n",
      "y_train:  (1158, 2)\n",
      "y_test:  (290, 2)\n"
     ]
    }
   ],
   "source": [
    "#obtaining the shape of test and train datasets\n",
    "X_train.shape\n",
    "X_test.shape\n",
    "y_train.shape\n",
    "y_test.shape\n",
    "print('X_shape: ',X_train.shape)\n",
    "print('X_test: ',X_test.shape)\n",
    "print('y_train: ',y_train.shape)\n",
    "print('y_test: ',y_test.shape)\n",
    "#print(No of training dataset or testing data set,no of features or labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.5.0-cp39-cp39-manylinux2010_x86_64.whl (454.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 454.4 MB 2.3 kB/s eta 0:00:011    |█▍                              | 20.1 MB 11.3 MB/s eta 0:00:39     |███▍                            | 48.1 MB 9.3 MB/s eta 0:00:44     |████▍                           | 62.3 MB 10.2 MB/s eta 0:00:39     |██████▍                         | 90.5 MB 7.3 MB/s eta 0:00:50     |████████▏                       | 115.5 MB 13.1 MB/s eta 0:00:26     |█████████▏                      | 130.5 MB 9.1 MB/s eta 0:00:36     |███████████▌                    | 163.6 MB 9.4 MB/s eta 0:00:32     |██████████████▏                 | 201.9 MB 8.6 MB/s eta 0:00:30     |██████████████▉                 | 210.8 MB 8.7 MB/s eta 0:00:28     |████████████████                | 226.3 MB 9.4 MB/s eta 0:00:25     |███████████████████             | 270.9 MB 8.9 MB/s eta 0:00:21     |████████████████████▍           | 289.8 MB 6.6 MB/s eta 0:00:26     |█████████████████████▎          | 302.2 MB 5.4 MB/s eta 0:00:29     |█████████████████████▉          | 310.0 MB 10.4 MB/s eta 0:00:14     |███████████████████████▏        | 328.6 MB 9.9 MB/s eta 0:00:13     |████████████████████████████▊   | 408.2 MB 9.4 MB/s eta 0:00:05     |█████████████████████████████▊  | 422.2 MB 10.1 MB/s eta 0:00:04\n",
      "\u001b[?25hCollecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp39-cp39-manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 9.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.9 MB 104 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 47 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /home/arvindn/anaconda3/envs/python39/lib/python3.9/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/arvindn/anaconda3/envs/python39/lib/python3.9/site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 7.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 118 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 6.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.17.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 7.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in /home/arvindn/anaconda3/envs/python39/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 7.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 7.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /home/arvindn/anaconda3/envs/python39/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 850 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/arvindn/anaconda3/envs/python39/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/arvindn/anaconda3/envs/python39/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow) (52.0.0.post20210125)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 6.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 7.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /home/arvindn/anaconda3/envs/python39/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.32.1-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 7.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 7.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /home/arvindn/anaconda3/envs/python39/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/arvindn/anaconda3/envs/python39/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/arvindn/anaconda3/envs/python39/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/arvindn/anaconda3/envs/python39/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 7.6 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=e678d6d1a5458b708a988ad559cca957da9131613317acafc5a1b15fc6aa522c\n",
      "  Stored in directory: /home/arvindn/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras-nightly, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.1\n",
      "    Uninstalling numpy-1.20.1:\n",
      "      Successfully uninstalled numpy-1.20.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "Successfully installed absl-py-0.13.0 astunparse-1.6.3 cachetools-4.2.2 flatbuffers-1.12 gast-0.4.0 google-auth-1.32.1 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels=y.shape[1]\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating model\n",
    "#here we have used 100,200,100 neurons in different layers\n",
    "#we have use relu activation function\n",
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               4100      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 44,602\n",
      "Trainable params: 44,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model summary for better understanding\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting loss function adn optimizer\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 1s 13ms/step - loss: 11.3941 - accuracy: 0.5915 - val_loss: 0.1618 - val_accuracy: 0.9655\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16184, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 4.3549 - accuracy: 0.7021 - val_loss: 0.1281 - val_accuracy: 0.9655\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16184 to 0.12808, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.8442 - accuracy: 0.8195 - val_loss: 0.1145 - val_accuracy: 0.9690\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.12808 to 0.11449, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.9881 - accuracy: 0.8765 - val_loss: 0.1078 - val_accuracy: 0.9724\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.11449 to 0.10780, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6290 - accuracy: 0.9214 - val_loss: 0.1065 - val_accuracy: 0.9793\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.10780 to 0.10652, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.9119 - val_loss: 0.1048 - val_accuracy: 0.9793\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.10652 to 0.10482, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.9413 - val_loss: 0.0976 - val_accuracy: 0.9793\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.10482 to 0.09765, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2684 - accuracy: 0.9534 - val_loss: 0.0888 - val_accuracy: 0.9793\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.09765 to 0.08882, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2991 - accuracy: 0.9585 - val_loss: 0.0912 - val_accuracy: 0.9828\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08882\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1479 - accuracy: 0.9724 - val_loss: 0.0850 - val_accuracy: 0.9828\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.08882 to 0.08503, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2407 - accuracy: 0.9577 - val_loss: 0.0760 - val_accuracy: 0.9828\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.08503 to 0.07599, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.9655 - val_loss: 0.0769 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.07599\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0913 - accuracy: 0.9767 - val_loss: 0.0745 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.07599 to 0.07446, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9758 - val_loss: 0.0677 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.07446 to 0.06768, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0932 - accuracy: 0.9801 - val_loss: 0.0747 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.06768\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0854 - accuracy: 0.9819 - val_loss: 0.0764 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.06768\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9845 - val_loss: 0.0738 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06768\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9862 - val_loss: 0.0612 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.06768 to 0.06125, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9888 - val_loss: 0.0677 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.06125\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9914 - val_loss: 0.0591 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.06125 to 0.05908, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9896 - val_loss: 0.0522 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.05908 to 0.05220, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.9888 - val_loss: 0.0544 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.05220\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9896 - val_loss: 0.0544 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.05220\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9853 - val_loss: 0.0496 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.05220 to 0.04962, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9922 - val_loss: 0.0476 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.04962 to 0.04760, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9940 - val_loss: 0.0442 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.04760 to 0.04417, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9931 - val_loss: 0.0470 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.04417\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0281 - accuracy: 0.9888 - val_loss: 0.0482 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.04417\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9922 - val_loss: 0.0514 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.04417\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.9888 - val_loss: 0.0511 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.04417\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.0494 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.04417\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9957 - val_loss: 0.0487 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.04417\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9905 - val_loss: 0.0465 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.04417\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9922 - val_loss: 0.0421 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.04417 to 0.04211, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9940 - val_loss: 0.0437 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.04211\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0326 - accuracy: 0.9948 - val_loss: 0.0451 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.04211\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0355 - accuracy: 0.9940 - val_loss: 0.0475 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.04211\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9922 - val_loss: 0.0438 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.04211\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0295 - accuracy: 0.9957 - val_loss: 0.0455 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.04211\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9948 - val_loss: 0.0436 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.04211\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9931 - val_loss: 0.0421 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.04211 to 0.04207, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9957 - val_loss: 0.0392 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.04207 to 0.03917, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9965 - val_loss: 0.0415 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.03917\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9948 - val_loss: 0.0393 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.03917\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0372 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.03917 to 0.03719, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.0418 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.03719\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.0492 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.03719\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 0.9965 - val_loss: 0.0483 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.03719\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9948 - val_loss: 0.0401 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.03719\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9965 - val_loss: 0.0397 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.03719\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9957 - val_loss: 0.0412 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.03719\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9974 - val_loss: 0.0428 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.03719\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9957 - val_loss: 0.0394 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.03719\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.9965 - val_loss: 0.0298 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.03719 to 0.02982, saving model to saved_models/audio_classification.hdf5\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9957 - val_loss: 0.0355 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.02982\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.0332 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.02982\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.0315 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.02982\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.0320 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.02982\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0338 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.02982\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9965 - val_loss: 0.0340 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.02982\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.0393 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.02982\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 0.9965 - val_loss: 0.0440 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.02982\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.0462 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.02982\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.0441 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.02982\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 0.0315 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.02982\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0350 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.02982\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 0.9965 - val_loss: 0.0394 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.02982\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.0365 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.02982\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0162 - accuracy: 0.9974 - val_loss: 0.0332 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.02982\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9983 - val_loss: 0.0359 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.02982\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.0366 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.02982\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0322 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.02982\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9983 - val_loss: 0.0370 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.02982\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.0402 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.02982\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.02982\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.0402 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.02982\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.02982\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.6990e-04 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.02982\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0441 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.02982\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.0459 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.02982\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9983 - val_loss: 0.0475 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.02982\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.0489 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.02982\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 0.9983 - val_loss: 0.0554 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.02982\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 0.9974 - val_loss: 0.0478 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.02982\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 0.9974 - val_loss: 0.0501 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.02982\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0020 - accuracy: 0.9991 - val_loss: 0.0515 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.02982\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 0.9974 - val_loss: 0.0490 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.02982\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.02982\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.0496 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.02982\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.1449e-04 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.02982\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.0497 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.02982\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 0.9983 - val_loss: 0.0409 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.02982\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 8.2424e-04 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.02982\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.0395 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.02982\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.0788e-04 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.02982\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.0331 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.02982\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.02982\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.02982\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.02982\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.0478 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.02982\n",
      "Training completed in time:  0:00:15.593065\n"
     ]
    }
   ],
   "source": [
    "## Trianing the model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 40\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9965517520904541\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print('Accuracy is',test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arvindn/anaconda3/envs/python39/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Testing Some Test Audio Data\n",
    "\n",
    "\n",
    "filename=audio_dataset_path+\"/Ball_Racket_Stairwell_01016_user.wav\"\n",
    "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "\n",
    "#print(mfccs_scaled_features)\n",
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "#print(mfccs_scaled_features)\n",
    "#print(mfccs_scaled_features.shape)\n",
    "predicted_label=model.predict_classes(mfccs_scaled_features)\n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
